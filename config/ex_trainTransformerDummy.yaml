model:
  base_learning_rate: 4.5e-06
  target: LatentPredictor.model.latentPredictor.Net2NetTransformer
  params:
    transformer_config:
      target: LatentPredictor.transformer.mingpt.GPT
      params:
        vocab_size: 16384
        block_size: 10000  # = 256 + 92 = dim(vqgan_latent_space,16x16) + dim(conditional_builder.embedding_dim)
        n_layer: 30
        n_head: 16
        n_embd: 1536
        embd_pdrop: 0.1
        resid_pdrop: 0.1
        attn_pdrop: 0.1
    first_stage_config:
      target: VQGAN.model.vqgan.DummyModel
      params:
        batch: 6
        

data:
  target: util.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 4
    train:
      target: data.smokeRing2.SmokeRingTrain
      params:
        root: /path/to/dataset/
        toTensor: True
        normalizeImage: True
    
    # validation:
    #   target: data.smokeRing.SmokeRingVal
    #   params:
    #     root: /path/to/dataset/
    #     toTensor: True
    #     normalizeImage: True
    #     normalizeParams: False


lightning:
  trainer:
    max_epochs: 200
    devices: 1
    accelerator: gpu