model:
  base_learning_rate: 4.5e-06
  target: LatentPredictor.model.latentPredictor.Net2NetTransformer
  params:
    transformer_config:
      target: LatentPredictor.transformer.mingpt.GPT
      params:
        vocab_size: 16384
        block_size: 600  # = 256 + 92 = dim(vqgan_latent_space,16x16) + dim(conditional_builder.embedding_dim)
        n_layer: 1
        n_head: 8
        n_embd: 1536
        embd_pdrop: 0.1
        resid_pdrop: 0.1
        attn_pdrop: 0.1
    first_stage_config:
      target: VQGAN.model.vqgan.VQModel
      params:
        ckpt_path: /path/to/model/data
        ignore_keys: ["loss"]
        embed_dim: 256
        n_embed: 16384
        ddconfig: 
            double_z: False
            z_channels: 256
            resolution: 512
            in_channels: 3
            out_ch: 3 
            ch: 64
            ch_mult: [1,2,4,8,8,8]
            num_res_blocks: 1
            attn_resolutions: [64]
            dropout: 0.0
        lossconfig:
          target: VQGAN.modules.losses.vqperceptual.DummyLoss

data:
  target: util.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 4
    train:
      target: data.smokeRing2.SmokeRingTrain
      params:
        root: /path/to/dataset
        toTensor: True
        normalizeImage: True
    
    # validation:
    #   target: data.smokeRing.SmokeRingVal
    #   params:
    #     root: /path/to/dataset
    #     toTensor: True
    #     normalizeImage: True
    #     normalizeParams: False


lightning:
  trainer:
    max_epochs: 200
    devices: 1
    accelerator: gpu